{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start building up our methodology by down-sizing the interaction dataset to a more manageable size. We choose to build our recommendation system using collaborative filtering algorithm. Matrix Factorization is out go-to class because of its effectiveness. The prediction results can be improved by assigning different regularization weights to the latent factors based on items' popularity and users' activeness. We will use Alternative Least Square (ASL) model from PySpark library as our first simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** PySpark library is more compatible with Google Colab, which we will be using to run the code. Hit the \"Open in Colab\" under the picture to have this notebook open in Google Colab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart](./images/flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ramilchai/capstone/blob/main/ALS_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Gl9CKAPQhx-V"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These following !pip install are for set up pyspark for Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oSkLAxYoG-a",
    "outputId": "b2416146-91ee-4b3c-b14b-ed25edc7d75c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 212.4 MB 67 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 59.5 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=3e449059925fcb10bd15ed41f0b040a0aa86f23a61ca63b71645dde656f7fc1d\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement openjdk-8-jdk-headless (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for openjdk-8-jdk-headless\u001b[0m\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-1.19.0-py3-none-any.whl (14.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.4 MB 63 kB/s \n",
      "\u001b[?25hCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 47.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.1)\n",
      "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 6.2 MB/s \n",
      "\u001b[?25hCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 51.1 MB/s \n",
      "\u001b[?25hCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.0)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
      "\u001b[?25hCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 45.0 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 46.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
      "Collecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.20)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 6.0 MB/s \n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.7.4.3)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (4.6.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.0)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->mlflow) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (2.4.7)\n",
      "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.11.0)\n",
      "Building wheels for collected packages: alembic, databricks-cli, prometheus-flask-exporter\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=745180ae719f2f2bc72e46277fe4eb317f702cc3d9eb1d24d0a8c8bb3407fa08\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100557 sha256=799da1ec0723ff8b2509f72686f6cf014294bd9f5158780d3c1bf4f10823693e\n",
      "  Stored in directory: /root/.cache/pip/wheels/3b/60/14/6930445b08959fbdf4e3029bac7e1f2cccb2e94df8afa00b29\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17416 sha256=7f0d9b6e0c270d70920859dcb27803769069d89ee41580dfb6e08acad87eee4a\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n",
      "Successfully built alembic databricks-cli prometheus-flask-exporter\n",
      "Installing collected packages: smmap, websocket-client, python-editor, Mako, gitdb, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed Mako-1.1.4 alembic-1.4.1 databricks-cli-0.14.3 docker-5.0.0 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 mlflow-1.19.0 prometheus-flask-exporter-0.18.2 python-editor-1.0.4 pyyaml-5.4.1 querystring-parser-1.2.4 smmap-4.0.0 websocket-client-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install openjdk-8-jdk-headless -qq\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our dataframe from the pickle file we dumped in the previous notebook (recommendation_book.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xKm9uTGMihFD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/content/interact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0cF3GLdYlEfn"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "# import org.apache.spark.sql.functions.col\n",
    "# import org.apache.spark.sql.types.IntegerType\n",
    "# import pyspark.sql.functions.col\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qy-GEj_QmEoV"
   },
   "source": [
    "### Set up Spark session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a SparkSession object and import the dataset into a PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zmPKgx24ot3C"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('bookrec').config('spark.driver.host', 'localhost')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kEfwt51wov6x"
   },
   "outputs": [],
   "source": [
    "df_sp = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4FrMPToqWut",
    "outputId": "e098b729-841e-4d77-af16-f36d804b7f9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_id_num', 'bigint'), ('book_id', 'bigint'), ('rating', 'bigint')]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nimJzK3l935"
   },
   "source": [
    "### First Simple Model (FSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building up our first simple model using ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jE_fSy2CqcGh"
   },
   "outputs": [],
   "source": [
    "(training, test) = df_sp.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G9fO3YndsODK"
   },
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5,rank=4, regParam=0.01, userCol='user_id_num', itemCol='book_id', ratingCol='rating',\n",
    "          coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YdcI40qtsapc"
   },
   "outputs": [],
   "source": [
    "fsm_model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ln_MiDXseLT",
    "outputId": "b4e9e47d-769d-419d-ef6f-c5dd8451d083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.623987864634006\n"
     ]
    }
   ],
   "source": [
    "predictions = fsm_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root-mean-square error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE from our FSM reads 1.62 which is not really good prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "596TJ6JBmWvr"
   },
   "source": [
    "### Tuning the Model with Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now optimize our FSM by using the built-in `CrossValidator` in PySpark with a suitable param grid and determine the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Wt2vUvDOlfGq"
   },
   "outputs": [],
   "source": [
    "als_model = ALS(userCol='user_id_num', itemCol='book_id', \n",
    "                ratingCol='rating', coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "43enPC0-nCqy"
   },
   "outputs": [],
   "source": [
    "params = ParamGridBuilder()\\\n",
    "          .addGrid(als_model.regParam, [0.01, 0.001, 0.1])\\\n",
    "          .addGrid(als_model.rank, [4, 10, 50]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Bg9_G2afnJmr"
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=als_model, \n",
    "                    estimatorParamMaps=params,\n",
    "                    evaluator=evaluator,\n",
    "                    parallelism=4)\n",
    "\n",
    "best_als_model = cv.fit(df_sp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwRVxKR1nulx",
    "outputId": "1d0ebc83-198b-43b9-9332-a1b12d1d7150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_als_model.bestModel.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxCeLngqplYz",
    "outputId": "2616a04e-dd6d-44a5-b899-21d69d40f9eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_defaultParamMap': {Param(parent='ALS_60d28e8bdf3b', name='blockSize', doc='block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data.'): 4096,\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='coldStartStrategy', doc=\"strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'.\"): 'nan',\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='itemCol', doc='column name for item ids. Ids must be within the integer value range.'): 'item',\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='userCol', doc='column name for user ids. Ids must be within the integer value range.'): 'user'},\n",
       " '_java_obj': JavaObject id=o5746,\n",
       " '_paramMap': {Param(parent='ALS_60d28e8bdf3b', name='coldStartStrategy', doc=\"strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'.\"): 'drop',\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='itemCol', doc='column name for item ids. Ids must be within the integer value range.'): 'book_id',\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='userCol', doc='column name for user ids. Ids must be within the integer value range.'): 'user_id_num'},\n",
       " '_params': [Param(parent='ALS_60d28e8bdf3b', name='blockSize', doc='block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data.'),\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='coldStartStrategy', doc=\"strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'.\"),\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='itemCol', doc='column name for item ids. Ids must be within the integer value range.'),\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='predictionCol', doc='prediction column name.'),\n",
       "  Param(parent='ALS_60d28e8bdf3b', name='userCol', doc='column name for user ids. Ids must be within the integer value range.')],\n",
       " 'blockSize': Param(parent='ALS_60d28e8bdf3b', name='blockSize', doc='block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data.'),\n",
       " 'coldStartStrategy': Param(parent='ALS_60d28e8bdf3b', name='coldStartStrategy', doc=\"strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'.\"),\n",
       " 'itemCol': Param(parent='ALS_60d28e8bdf3b', name='itemCol', doc='column name for item ids. Ids must be within the integer value range.'),\n",
       " 'predictionCol': Param(parent='ALS_60d28e8bdf3b', name='predictionCol', doc='prediction column name.'),\n",
       " 'uid': 'ALS_60d28e8bdf3b',\n",
       " 'userCol': Param(parent='ALS_60d28e8bdf3b', name='userCol', doc='column name for user ids. Ids must be within the integer value range.')}"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_als_model.bestModel.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0_jmkf32N0U"
   },
   "source": [
    "### Best ALS Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally get our best ALS model with suitable hyperparameters: `maxIter`=5; `rank`=50; and `regParam`=0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "euNxK-I22TOK"
   },
   "outputs": [],
   "source": [
    "best_als = ALS(maxIter=5,rank=50, regParam=0.1, userCol='user_id_num', itemCol='book_id', \n",
    "                ratingCol='rating', coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "pKAFMWIG2pD2"
   },
   "outputs": [],
   "source": [
    "best_als_model = best_als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQp4Bwyr2x42",
    "outputId": "2f7d6a7e-4f13-4cbf-e6fb-9efd47fa6f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.092242472532004\n"
     ]
    }
   ],
   "source": [
    "best_als_predictions = best_als_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(best_als_predictions)\n",
    "print('Root-mean-square error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqYftF9I3TkW"
   },
   "source": [
    "RMSE from our best ALS model reads 1.09, which is way better than our FSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6dMpRaMM3EcaRMdLudqv3",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ALS_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
